"""
This module contains various functions used in testing Xpedite profiling and comparing
results.

Author:  Brooke Elizabeth Cantwell, Morgan Stanley
"""

import os
import copy
from test_xpedite.test_profiler.app         import TargetLauncher
from test_xpedite                           import TXN_COUNT, XPEDITE_APP_INFO_PATH
from test_xpedite.test_profiler.comparator  import findDiff
from xpedite.profiler.probeAdmin            import ProbeAdmin

REPORT_NAME = 'XpediteTest'
SAMPLE_FILE_PATH = '{}/xpedite-*-{}-[0-9]*.data'

def generateProfiles(app, scenario):
  """
  Start Xpedite profiling and return the profiles and result generating by profiling
  """
  from xpedite.profiler import Profiler
  result = Profiler.profile(
    app, scenario.profileInfo, REPORT_NAME, None, app.dryRun, scenario.result,
    interactive=False, heartbeatInterval=1
  )
  return result.profiles

def runXpediteReport(runId, context, scenario, sampleFilePath=None, cpuInfoOverride=False):
  """
  Run xpedite report
  """
  with scenario.makeXpediteDormantApp(runId, context.workspace, sampleFilePath) as xpediteApp:
    if cpuInfoOverride:
      xpediteApp.env.proxy.fullCpuInfo = scenario.fullCpuInfo
    xpediteApp.appInfoPath = os.path.join(scenario.dataDir, XPEDITE_APP_INFO_PATH)
    profiles = generateProfiles(xpediteApp, scenario)
    return profiles

def runXpediteRecord(context, scenario):
  """
  Run xpedite record against a live target application process
  """
  with TargetLauncher(context, scenario) as app:
    profiles = generateProfiles(app.xpediteApp, scenario)
    fullCpuInfo = copy.deepcopy(app.xpediteApp.env.proxy.fullCpuInfo)
    dataFiles = app.xpediteApp.gatherFiles(app.xpediteApp.sampleFilePattern())
  return app, profiles, fullCpuInfo, dataFiles

def loadProbes(context, scenario):
  """
  Generate a probe map to test the state of application probes
  """
  with TargetLauncher(context, scenario) as app:
    return ProbeAdmin.loadProbes(app.xpediteApp)

def compareVsBaseline(context, scenario):
  """
  Compare profiles with benchmarks and profiles without benchmarks against existing profiles
  """
  runId = scenario.discoverRunId()
  sampleFilePath = SAMPLE_FILE_PATH.format(scenario.dataDir, runId)
  reportProfiles = runXpediteReport(
    runId, context, scenario, sampleFilePath=sampleFilePath, cpuInfoOverride=True
  )
  reportProfiles.transactionRepo = None
  reportProfiles.cpuInfo.cpuId = scenario.cpuId
  if scenario.benchmarkPaths:
    benchmarkCount = len(scenario.benchmarkPaths)
    validateBenchmarks(reportProfiles, benchmarkCount)
  findDiff(reportProfiles.__dict__, scenario.baselineProfiles.__dict__)
  assert reportProfiles == scenario.baselineProfiles

def validateBenchmarks(profiles, benchmarkCount):
  """
  Validate the number of benchmark and number of timelines per benchmark
  """
  for profile in profiles:
    assert len(profile.benchmarks) == benchmarkCount
    for benchmark in profile.benchmarks.keys():
      assert len(profile.benchmarks[benchmark].timelineCollection) == TXN_COUNT

def buildNotebook(context, scenario):
  """
  Test to confirm a Jupyter notebook can be creating from profile information and results
  generated by xpedite record
  """
  import xpedite.jupyter.driver
  from xpedite.jupyter            import DATA_DIR, DATA_FILE_EXT, NOTEBOOK_EXT
  from xpedite.benchmark          import makeBenchmark
  from test_xpedite               import mkdtemp
  app, _, fullCpuInfo, dataFiles = runXpediteRecord(context, scenario)
  runId = app.xpediteApp.runId
  notebookDir = mkdtemp()
  tempDataDir = os.path.join(notebookDir, DATA_DIR)
  os.mkdir(tempDataDir)
  notebookPath = os.path.join(notebookDir, '{}{}'.format(REPORT_NAME, NOTEBOOK_EXT))
  dataFilePath = os.path.join(notebookDir, DATA_DIR, '{}{}'.format(REPORT_NAME, DATA_FILE_EXT))
  notebook = xpedite.jupyter.driver.buildNotebook(
    scenario.appName, scenario.result, notebookPath, dataFilePath, runId
  )
  return notebook, dataFilePath, app, fullCpuInfo, dataFiles
